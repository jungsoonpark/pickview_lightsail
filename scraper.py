import pandas as pd
from playwright.sync_api import sync_playwright
import time
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime
import traceback

# âœ… êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
SHEET_ID = '1Ew7u6N72VP3nVvgNiLKZDyIpHg4xXz-prkyV4SW7EkI'
JSON_KEY = 'pickview-be786ad8e194.json'
READ_SHEET_NAME = 'list'       # í‚¤ì›Œë“œ ì‹œíŠ¸
WRITE_SHEET_NAME = 'result'    # ê²°ê³¼ ì €ì¥ ì‹œíŠ¸

# âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
def connect_to_google_sheet(sheet_name):
    try:
        scopes = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]
        creds = Credentials.from_service_account_file(JSON_KEY, scopes=scopes)
        client = gspread.authorize(creds)
        sheet = client.open_by_key(SHEET_ID).worksheet(sheet_name)
        print(f"âœ… êµ¬ê¸€ ì‹œíŠ¸ '{sheet_name}' ì—°ê²° ì„±ê³µ")
        return sheet
    except Exception as e:
        print(f"[ERROR] êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        exit()

# âœ… í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸° (ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€)
def get_keywords_from_google_sheet():
    sheet = connect_to_google_sheet(READ_SHEET_NAME)
    data = sheet.get_all_records()
    today = datetime.today().strftime('%Y-%m-%d')
    keywords = [row['keyword'] for row in data if str(row['date']) == today]
    print(f"âœ… {len(keywords)}ê°œì˜ í‚¤ì›Œë“œë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤: {keywords}")
    return keywords

# âœ… êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥
def save_results_to_google_sheet(results):
    try:
        sheet = connect_to_google_sheet(WRITE_SHEET_NAME)
        sheet.clear()
        sheet.append_row(["date", "keyword", "product_id"])
        for row in results:
            sheet.append_row(row)
        print(f"âœ… êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ ì™„ë£Œ: https://docs.google.com/spreadsheets/d/{SHEET_ID}/edit")
    except Exception as e:
        print(f"[ERROR] êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        traceback.print_exc()

# âœ… ìƒí’ˆ ID ìˆ˜ì§‘
def scrape_product_ids(keyword):
    try:
        print(f"\nğŸŸ¢ '{keyword}' í¬ë¡¤ë§ ì‹œì‘")
        with sync_playwright() as p:
            print(f"[DEBUG] Playwright ì‹œì‘")
            browser = p.chromium.launch(
                headless=True,
                args=["--disable-blink-features=AutomationControlled"]
            )
            context = browser.new_context(
                locale='ko-KR',
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'
            )
            page = context.new_page()

            url = f'https://www.aliexpress.com/wholesale?SearchText={keyword}&SortType=total_tranpro_desc'
            print(f"[INFO] ê²€ìƒ‰ URL: {url}")

            try:
                page.goto(url, timeout=60000)
                print(f"[INFO] '{keyword}' í˜ì´ì§€ ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                print(f"[ERROR] '{keyword}' í˜ì´ì§€ ì§„ì… ì‹¤íŒ¨: {e}")
                browser.close()
                return []

            time.sleep(2)

            selectors = [
                'div[data-spm="itemlist"] a[href*="/item/"]',
                'a[itemprop="url"]',
                'a[href*="/item/"]'
            ]

            elements = []
            for selector in selectors:
                try:
                    print(f"[INFO] ì…€ë ‰í„° ì‹œë„: {selector}")
                    page.wait_for_selector(selector, timeout=10000)
                    elements = page.query_selector_all(selector)
                    print(f"[INFO] ì…€ë ‰í„° '{selector}' - ì°¾ì€ ìš”ì†Œ ìˆ˜: {len(elements)}")
                    if elements:
                        print(f"[SUCCESS] ìœ íš¨í•œ ì…€ë ‰í„° ì°¾ìŒ: {selector}")
                        break
                except Exception as e:
                    print(f"[WARNING] ì…€ë ‰í„° '{selector}' ì‹¤íŒ¨: {e}")

            if not elements:
                print(f"[ERROR] '{keyword}' ìœ íš¨í•œ ì…€ë ‰í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                browser.close()
                return []

            product_ids = []
            for element in elements[:5]:
                href = element.get_attribute('href')
                if href:
                    try:
                        product_id = href.split('/')[-1].split('.')[0]
                        product_ids.append(product_id)
                        print(f"[INFO] ìƒí’ˆ ID ì¶”ì¶œ: {product_id}")
                    except Exception as e:
                        print(f"[WARNING] href íŒŒì‹± ì‹¤íŒ¨: {href} / {e}")

            browser.close()
            print(f"[DEBUG] ë¸Œë¼ìš°ì € ì •ìƒ ì¢…ë£Œ")

            print(f"âœ… í‚¤ì›Œë“œ '{keyword}'ì—ì„œ {len(product_ids)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ.")
            return product_ids

    except Exception as e:
        print(f"[CRITICAL ERROR] '{keyword}' í¬ë¡¤ë§ ë„ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        traceback.print_exc()
        return []

# âœ… ë©”ì¸ ì‹¤í–‰
def main():
    print("[START] í”„ë¡œê·¸ë¨ ì‹œì‘")
    keywords = get_keywords_from_google_sheet()
    all_results = []
    today = datetime.today().strftime('%Y-%m-%d')

    for keyword in keywords:
        print(f"\n[PROCESS] í‚¤ì›Œë“œ ì§„í–‰: {keyword}")
        product_ids = scrape_product_ids(keyword)
        for product_id in product_ids:
            all_results.append([today, keyword, product_id])
        print(f"[WAIT] ë‹¤ìŒ í‚¤ì›Œë“œê¹Œì§€ ëŒ€ê¸° ì¤‘...\n")
        time.sleep(2)

    save_results_to_google_sheet(all_results)
    print("ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")

if __name__ == '__main__':
    main()
